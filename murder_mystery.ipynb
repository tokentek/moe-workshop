{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_model_client_4o\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat, MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def create_and_get_assistant_agent(\n",
    "        name: str,\n",
    "        description: str,\n",
    "        system_message: str,\n",
    "        tools: list[Callable] = [],\n",
    "        model_client: str = '4o'\n",
    "    ) -> AssistantAgent:\n",
    "\n",
    "    model_client = get_model_client_4o()\n",
    "    return AssistantAgent(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        model_client=model_client,\n",
    "        system_message=system_message,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "def get_user_proxy_agent() -> UserProxyAgent:\n",
    "    return UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    input_func=input,\n",
    "    #human_input_mode=\"NEVER\",\n",
    "    #default_auto_reply=\"Please continue if there is anything else you need help with.\",\n",
    "    #max_turns=10\n",
    "    )\n",
    "\n",
    "async def get_agent_response(agent: AssistantAgent, task: str) -> str:\n",
    "    messages = []\n",
    "    messages.append(TextMessage(content=task, source=\"user\"))\n",
    "    response = await agent.on_messages(\n",
    "    messages, CancellationToken()\n",
    "    )\n",
    "    return response.chat_message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils\n",
    "def read_markdown_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads a .md (Markdown) file and returns its content as a string.\n",
    "    \n",
    "    Parameters:\n",
    "        filepath (str): Path to the markdown file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Contents of the markdown file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreakrogdal/repos/moe-workshop/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:413: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    }
   ],
   "source": [
    "assistant_clara = create_and_get_assistant_agent(\n",
    "    name='clara',\n",
    "    description='Long-time personal assistant to the late Dr. Felix Lang',\n",
    "    system_message=read_markdown_file('character_system_msgs/assistent_clara.md')\n",
    "    )\n",
    "chef_mario = create_and_get_assistant_agent(\n",
    "    name='mario',\n",
    "    description='Head caterer for the event',\n",
    "    system_message=read_markdown_file('character_system_msgs/chef_mario.md')\n",
    "    )\n",
    "dr_biologist_alina = create_and_get_assistant_agent(\n",
    "    name='alina',\n",
    "    description='Molecular biologist and former colleague of the late Dr. Felix Lang',\n",
    "    system_message=read_markdown_file('character_system_msgs/dr_biologist_alina.md')\n",
    "    )\n",
    "intern_jonas = create_and_get_assistant_agent(\n",
    "    name='jonas',\n",
    "    description='Young intern tasked with tech setup at the gala',\n",
    "    system_message=read_markdown_file('character_system_msgs/intern_jonas.md')\n",
    "    )\n",
    "investor_henrik = create_and_get_assistant_agent(\n",
    "    name='henrik',\n",
    "    description='Major investor in Dr. Lang’s research projectsa',\n",
    "    system_message=read_markdown_file('character_system_msgs/investor_henrik.md')\n",
    "    )\n",
    "journalist_eva = create_and_get_assistant_agent(\n",
    "    name='eva',\n",
    "    description='An investigative journalist known for publishing exposés',\n",
    "    system_message=read_markdown_file('character_system_msgs/journalist_eva.md')\n",
    "    )\n",
    "\n",
    "detective = create_and_get_assistant_agent(\n",
    "    name='detective',\n",
    "    description='A private detective hired by the Lang family to investigate the murder of Dr. Felix Lang',\n",
    "    system_message=read_markdown_file('character_system_msgs/detective.md')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**You are Clara Nyberg**, long-time personal assistant to the late Dr. Felix Lang. You were present during the entire evening of the garden gala and are aware of everyone’s movements and behaviors. You are organized, detail-oriented, and somewhat protective of Dr. Lang’s legacy.\n",
       "\n",
       "You will answer all questions politely and truthfully **based on what you observed**, but you will **not voluntarily share personal or sensitive information**, especially if it reflects poorly on you or others (e.g., your knowledge of future job cuts).\n",
       "\n",
       "If someone asks a **direct question** that touches on sensitive information, you may:\n",
       "- Deflect slightly (e.g., \"I’m not sure that’s relevant\")\n",
       "- Give a **partial** but **factually correct** response\n",
       "- Respond with a vague or cautious tone\n",
       "\n",
       "Always answer from Clara’s point of view, using professional, composed language. You are not emotional, but you are under quiet stress and want to avoid trouble.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
