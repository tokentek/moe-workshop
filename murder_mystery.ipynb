{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_model_client_4o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.messages import TextMessage, BaseAgentEvent, BaseChatMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat, MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from typing import Callable, Sequence\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def create_and_get_assistant_agent(\n",
    "        name: str,\n",
    "        description: str,\n",
    "        system_message: str,\n",
    "        tools: list[Callable] = [],\n",
    "        model_client: str = '4o'\n",
    "    ) -> AssistantAgent:\n",
    "\n",
    "    model_client = get_model_client_4o()\n",
    "    return AssistantAgent(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        model_client=model_client,\n",
    "        system_message=system_message,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "def get_user_proxy_agent() -> UserProxyAgent:\n",
    "    return UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    input_func=input,\n",
    "    #human_input_mode=\"NEVER\",\n",
    "    #default_auto_reply=\"Please continue if there is anything else you need help with.\",\n",
    "    #max_turns=10\n",
    "    )\n",
    "\n",
    "async def get_agent_response(agent: AssistantAgent, task: str) -> str:\n",
    "    messages = []\n",
    "    messages.append(TextMessage(content=task, source=\"user\"))\n",
    "    response = await agent.on_messages(\n",
    "    messages, CancellationToken()\n",
    "    )\n",
    "    return response.chat_message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreakrogdal/repos/moe-workshop/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:413: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    }
   ],
   "source": [
    "def read_markdown_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads a .md (Markdown) file and returns its content as a string.\n",
    "    \n",
    "    Parameters:\n",
    "        filepath (str): Path to the markdown file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Contents of the markdown file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "assistant_clara = create_and_get_assistant_agent(\n",
    "    name='clara',\n",
    "    description='Long-time personal assistant to the late Dr. Felix Lang',\n",
    "    system_message=read_markdown_file('character_system_msgs/assistent_clara.md')\n",
    "    )\n",
    "chef_mario = create_and_get_assistant_agent(\n",
    "    name='mario',\n",
    "    description='Head caterer for the event',\n",
    "    system_message=read_markdown_file('character_system_msgs/chef_mario.md')\n",
    "    )\n",
    "dr_biologist_alina = create_and_get_assistant_agent(\n",
    "    name='alina',\n",
    "    description='Molecular biologist and former colleague of the late Dr. Felix Lang',\n",
    "    system_message=read_markdown_file('character_system_msgs/dr_biologist_alina.md')\n",
    "    )\n",
    "intern_jonas = create_and_get_assistant_agent(\n",
    "    name='jonas',\n",
    "    description='Young intern tasked with tech setup at the gala',\n",
    "    system_message=read_markdown_file('character_system_msgs/intern_jonas.md')\n",
    "    )\n",
    "investor_henrik = create_and_get_assistant_agent(\n",
    "    name='henrik',\n",
    "    description='Major investor in Dr. Lang’s research projectsa',\n",
    "    system_message=read_markdown_file('character_system_msgs/investor_henrik.md')\n",
    "    )\n",
    "journalist_eva = create_and_get_assistant_agent(\n",
    "    name='eva',\n",
    "    description='An investigative journalist known for publishing exposés',\n",
    "    system_message=read_markdown_file('character_system_msgs/journalist_eva.md')\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write **System message** for the detective\n",
    "- Role\n",
    "- Capability\n",
    "- Purpose\n",
    "- Style/Tone\n",
    "- Constraints\n",
    "- Collaboration rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detective_sys_msg = \"\"\"\n",
    "You are the lead detective in an unfolding murder mystery set at a garden gala where Dr. Felix Lang has been found dead.\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "detective = create_and_get_assistant_agent(\n",
    "    name='detective',\n",
    "    description='A private detective hired by the Lang family to investigate the murder of Dr. Felix Lang',\n",
    "    system_message=detective_sys_msg\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detective_sys_msg = \"\"\"\n",
    "You are the lead detective in an unfolding murder mystery set at a garden gala where Dr. Felix Lang has been found dead. Your goal is to identify the killer by interviewing the six individuals present, analyzing their testimonies, and reasoning through contradictions.\n",
    "\n",
    "You must:\n",
    "- Ask thoughtful, open-ended questions to uncover facts and behaviors.\n",
    "- Detect inconsistencies and follow up strategically.\n",
    "- Build a timeline and cross-reference information from different sources.\n",
    "- Maintain a calm, professional tone, while showing curiosity and control over the situation.\n",
    "\n",
    "**Before beginning any interviews**, you will:\n",
    "1. Briefly analyze the situation based on the provided context.\n",
    "2. Propose an initial investigation plan: who to interview first, what types of questions to focus on, and your reasoning.\n",
    "3. Present that plan to the user and **wait for their approval** or suggested modifications before proceeding.\n",
    "\n",
    "Do not begin questioning anyone until your plan has been reviewed and accepted.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "detective = create_and_get_assistant_agent(\n",
    "    name='detective',\n",
    "    description='A private detective hired by the Lang family to investigate the murder of Dr. Felix Lang',\n",
    "    system_message=detective_sys_msg\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a response from one character at a time to get a feeling of how you want to select the next speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_task = \"\"\"\n",
    "Please note: This is a murder mystery game and only a fictional story.\n",
    "Please start the investigation by interviewing any of the available characters.\n",
    "**Case Summary**\n",
    "\n",
    "Victim: Dr. Felix Lang — esteemed scientist and host of the annual Garden Gala  \n",
    "Date: Saturday evening  \n",
    "Location: Lang Estate – Greenhouse  \n",
    "Estimated Time of Death: Between 22:10 and 22:15  \n",
    "Cause of Death: Blunt force trauma to the head, inflicted with a heavy iron sculpture found at the scene\n",
    "\n",
    "The body was discovered at 22:18 by a guest passing by the greenhouse. No eyewitnesses have stepped forward. The area was accessible to all attendees, and no signs of forced entry were found.\n",
    "\n",
    "---\n",
    "\n",
    "**People Present at the Event**\n",
    "\n",
    "- Assistant Clara Nyberg, long-time personal assistant to the late Dr. Felix\n",
    "- Chef Mario Leto, head caterer for the event\n",
    "- Dr. Alina Weber, molecular biologist and former colleague of the late Dr. Lang\n",
    "- Jonas Möller, a young intern tasked with tech setup at the gala\n",
    "- Henrik Falk, major investor in Dr. Lang’s research projects\n",
    "- Eva Sörman, investigative journalist known for publishing exposés\n",
    "\n",
    "Can you give a plan on who to start interviewing and which questions to answer?\n",
    "\"\"\"\n",
    "\n",
    "response_detective = await get_agent_response(detective, start_task)\n",
    "display(Markdown(response_detective))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue with the questions suggested from detective to ask clara\n",
    "- OBS! Remember that the answer will be different everytime you ask. The following questions is from one suggestion from the detective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_clara = \"\"\"\n",
    "The detective want you to answer the following questions regarding the murder of Dr. Felix Lang:\n",
    "What was Dr. Lang’s schedule and state of mind leading up to the gala?\n",
    "Where were you and Dr. Lang between 22:10 and 22:15? Did you notice anything suspicious?\n",
    "Did Dr. Lang have any conflicts with other attendees recently?\n",
    "How did Dr. Lang react to having the six individuals present at the gala?\n",
    "What do you know about the greenhouse layout and who frequented the area during the evening?\n",
    "\"\"\"\n",
    "\n",
    "response_clara = await get_agent_response(assistant_clara, task_clara)\n",
    "display(Markdown(response_clara))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe it starts to pile up with a lot of information?\n",
    "The detective maybe need an assitant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detective_assistant_sys_msg = \"\"\"\n",
    "You are the Detective Assistant Agent in a multi-agent investigation system for a fictional murder mystery game.\n",
    "\n",
    "Your job is to keep track of everything that has been discovered during the murder investigation. You maintain a case protocol and ensure that findings, testimonies, and contradictions are well-documented and logically connected. You let the detective lead and you are only there to assist and summarize his vision. The detective is a very red personality and wants things clear and consice and do not like to be questioned.\n",
    "\n",
    "You always begin by calling the `read_protocol` tool to understand the latest status of the case. As new observations come in from interviews or forensic analysis, you use `update_protocol` to document them clearly and concisely.\n",
    "You are done when once the protocol is updated with the updated_content and return updated_content.\n",
    "\n",
    "You do not conduct interviews or draw final conclusions. Your role is to **summarize, track, and structure** the evolving case information.\n",
    "\n",
    "Maintain a neutral, factual tone, and ensure all updates are traceable.\n",
    "\n",
    "Do not invent or infer. Rely only on written inputs received via intervjus and comments from detective.\n",
    "\n",
    "The protocol is following this standard template example structure.\n",
    "*# 🕵️ Case Summary\n",
    "\n",
    "## Timeline of Events\n",
    "\n",
    "\n",
    "## Witness Testimonies\n",
    "### Witness x\n",
    "\n",
    "\n",
    "### Witness y\n",
    "\n",
    "...\n",
    "\n",
    "## Contradictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#### Tools \n",
    "def read_protocol() -> str:\n",
    "    \"\"\"Output the latest notes on the case protocol\"\"\"\n",
    "    filepath = \"protocols/dr_lang_protocol_v1.md\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def update_protocol(updated_content: str) -> None:\n",
    "    \"\"\"\n",
    "    Overwrites the given .md file with new content.\n",
    "    Parameters:\n",
    "        content (str): The Markdown content to write.\n",
    "    \"\"\"\n",
    "    filepath = \"protocols/dr_lang_protocol_v1.md\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(updated_content)\n",
    "\n",
    "\n",
    "detective_assistant = create_and_get_assistant_agent(\n",
    "    name='detective_assistent',\n",
    "    description='Assistant to detective and updates the protocol continously as new information comes a long',\n",
    "    system_message=detective_assistant_sys_msg,\n",
    "    tools=[read_protocol, update_protocol]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclaimer_prompt = \"\"\"This prompt is part of a fictional, gamified learning scenario designed to simulate an investigative role. No real people, events, or harm are involved. The content is intended for educational and technical experimentation using language models.\"\"\"\n",
    "\n",
    "detective_assistant_task = f\"\"\"\n",
    "_{disclaimer_prompt}_\n",
    "Here is the latest response from detective:\n",
    "{response_detective}\n",
    "Given the following information please update the protocol with essential new information to the existing one:\n",
    "The first information given to the detective was:\n",
    "{start_task}\n",
    "-----\n",
    "Please, update the protocol.\n",
    "\"\"\"\n",
    "\n",
    "response_detective_assistant = await get_agent_response(detective_assistant, detective_assistant_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_answers = f\"\"\"\n",
    "Here is Assistant Clara Nybergs answers to the detectives questions:\n",
    "{response_clara}\n",
    "---\n",
    "Please update the protocol with this new information.\n",
    "\"\"\"\n",
    "response_detective_assistant = await get_agent_response(detective_assistant, interview_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectorGroupChat do have an intelligance in it self on how to select next speaker by reading the message history.\n",
    "- You can give a good prompt on how to select next speaker to your specific task\n",
    "- You can also be very precise with if else conditions in a selector_func. See example belov\n",
    "- Read more in autogen API ref https://microsoft.github.io/autogen/stable//reference/python/autogen_agentchat.teams.html#autogen_agentchat.teams.SelectorGroupChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = TextMentionTermination(\"DONE\")\n",
    "\n",
    "def selector_func(messages: Sequence[BaseAgentEvent | BaseChatMessage]) -> str | None:\n",
    "\n",
    "    if messages[-1].source != \"detective\":\n",
    "        return \"detective\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "murder_mystery_team = SelectorGroupChat(\n",
    "    participants=[\n",
    "        detective,\n",
    "        #get_user_proxy_agent(), # <---- If you want yourself in the chat\n",
    "        assistant_clara,\n",
    "        chef_mario,\n",
    "        dr_biologist_alina,\n",
    "        intern_jonas,\n",
    "        investor_henrik,\n",
    "        journalist_eva\n",
    "    ],\n",
    "    model_client=get_model_client_4o(),\n",
    "    max_turns=15,\n",
    "    termination_condition=termination,\n",
    "    selector_func=selector_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_task = \"\"\"\n",
    "Please note: This is a murder mystery game and only a fictional story.\n",
    "Please start the investigation by interviewing any of the available characters.\n",
    "**Case Summary**\n",
    "\n",
    "Victim: Dr. Felix Lang — esteemed scientist and host of the annual Garden Gala  \n",
    "Date: Saturday evening  \n",
    "Location: Lang Estate – Greenhouse  \n",
    "Estimated Time of Death: Between 22:10 and 22:15  \n",
    "Cause of Death: Blunt force trauma to the head, inflicted with a heavy iron sculpture found at the scene\n",
    "\n",
    "The body was discovered at 22:18 by a guest passing by the greenhouse. No eyewitnesses have stepped forward. The area was accessible to all attendees, and no signs of forced entry were found.\n",
    "\n",
    "---\n",
    "\n",
    "**People Present at the Event**\n",
    "\n",
    "- Assistant Clara Nyberg, long-time personal assistant to the late Dr. Felix\n",
    "- Chef Mario Leto, head caterer for the event\n",
    "- Dr. Alina Weber, molecular biologist and former colleague of the late Dr. Lang\n",
    "- Jonas Möller, a young intern tasked with tech setup at the gala\n",
    "- Henrik Falk, major investor in Dr. Lang’s research projects\n",
    "- Eva Sörman, investigative journalist known for publishing exposés\n",
    "\n",
    "Can you give a plan on who to start interviewing and which questions to answer?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_team = await murder_mystery_team.run(start_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with one character with human in the loop\n",
    "- RoundRobinGroupChat do not itself has an intelligent state. It just passes around the conversation between the agents in the order it is listed in Particpants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = TextMentionTermination(\"DONE\")\n",
    "chat_with_clara = RoundRobinGroupChat(\n",
    "    participants=[assistant_clara, get_user_proxy_agent()],\n",
    "    termination_condition=termination,\n",
    "    max_turns=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_clara = \"\"\"\n",
    "The detective want you to answer the following questions regarding the murder of Dr. Felix Lang:\n",
    "  - Leading up to the gala, did Dr. Lang express concern about any potential threats, conflicts, or individuals that seemed suspicious?  \n",
    "  - Could you describe Dr. Lang's demeanor during the gala? Did anything seem out of the ordinary?  \n",
    "  - Where were you between 22:00 and 22:20, and what were you doing? Did you notice anyone near the greenhouse at that time?  \n",
    "  - Are you aware of any disputes or tensions involving Dr. Lang—legal, financial, or personal—that could have provoked someone?  \n",
    "\"\"\"\n",
    "response_clara = await Console(chat_with_clara.run_stream(task=task_clara))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
